name: Kuber_cluster_monitoring

on:
  schedule:
    - cron: '*/60 * * * *'
  workflow_dispatch:

jobs:
  build:
    name: build
    runs-on: ubuntu-latest
    outputs: 
       check_failed: ${{ steps.init.outputs.check_failed }}
    steps:
      - uses: actions/checkout@v2
      - name: Check for failed pods
        uses: appleboy/ssh-action@v1.1.0
        with:
          proxy_host: ${{ secrets.JUMPHOST_IP }}
          proxy_port: ${{ secrets.JUMPHOST_PORT }}
          proxy_username: ${{ secrets.JUMPHOST_USER }}
          proxy_password: ${{ secrets.JUMPHOST_PASS }}
          host: ${{ secrets.K9S_SERVER_IP }}
          username: ${{ secrets.K9S_SERVER_USER }}
          password: ${{ secrets.K9S_SERVER_PASS }}
          script: |
            kubectl config use-context k8s --kubeconfig ~/.kube/config-k8s
            kubectl --kubeconfig ~/.kube/config-k8s get pods -A > k8s_status.log
            kubectl config use-context k3s --kubeconfig ~/.kube/config-k3s
            kubectl --kubeconfig ~/.kube/config-k3s get pods -A > k3s_status.log
            grep -E "Error" ~/k3s_status.log ~/k8s_status.log > Monitoring.txt
            if grep -q Error ~/Monitoring.txt; then
              echo "check_failed=true" >> "$GITHUB_OUTPUT"
            else
              echo "check_failed=false" >> "$GITHUB_OUTPUT"
            fi
            
  notification:
    needs: build
    runs-on: ubuntu-latest
    if: needs.build.outputs.check_failed == true
    steps:
    - name: Slack Notification on Failure
      uses: rtCamp/action-slack-notify@v2  
      env:
        SLACK_COLOR: failure
        SLACK_MESSAGE: "You have some failed pods in your cluster"
        SLACK_TITLE: Kuber Failed Pods
        SLACK_USERNAME: KuberCluster
        SLACK_WEBHOOK: ${{ secrets.HOOK }}
